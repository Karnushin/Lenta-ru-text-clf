{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "\n",
    "https://www.kaggle.com/yutkin/corpus-of-russian-news-articles-from-lenta/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from category_encoders import TargetEncoder, BinaryEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import multiprocessing\n",
    "import datetime\n",
    "from pycm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "stopwords_rus_dict = Counter(russian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#фиксация random_state\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выгрузка всех данных\n",
    "#data_all = pd.read_csv('news_lenta.csv')\n",
    "#data_all.iloc[:100*1000,:].to_csv('part_news_lenta.csv', index=False)\n",
    "#удалил целый файл news_lenta.csv, тк он оч тяжелый, оставил первые 100к строк в part_news_lenta.csv\n",
    "data_all = pd.read_csv('part_news_lenta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropColumns(df, columns_list):\n",
    "    '''Удаление столбцов в датафрейме'''\n",
    "    return df.drop(columns_list, axis = 1)\n",
    "\n",
    "def HandleMissedData(df, method='skip'):\n",
    "    '''В tags есть данные с пропусками, применим 2 стратегии: удаление,\n",
    "    замена на новое значение'''\n",
    "    if method == 'delete':\n",
    "        #пропуски составляют менее 5% от выборки, что является весьма малым и \n",
    "        #имеет смысл попробовать их просто удалить\n",
    "        return df.dropna()\n",
    "    else:\n",
    "        return df.fillna(value='Пропуск')\n",
    "\n",
    "def EncodeTarget(y):\n",
    "    '''Для представения целевой переменной в численно виде'''\n",
    "    lab_enc = LabelEncoder()\n",
    "    return lab_enc.fit_transform(y)\n",
    "\n",
    "def EncodeTags(train, test, validation, method='ohe'):\n",
    "    '''Кодировка tags'''\n",
    "    \n",
    "    if method == 'ohe':\n",
    "        one_hot_enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        train = (one_hot_enc.fit_transform(train.values.reshape(-1,1)))\n",
    "        test = (one_hot_enc.transform(test.values.reshape(-1,1)))\n",
    "        validation = (one_hot_enc.transform(validation.values.reshape(-1,1)))\n",
    "    #использовалось еще при применении деревьев\n",
    "    elif method == 'target':\n",
    "        targ_enc = TargetEncoder().fit(train.values, y_train)\n",
    "        train = targ_enc.transform(train.values)\n",
    "        test = targ_enc.transform(test.values)\n",
    "        validation = targ_enc.transform(validation.values)\n",
    "    return train, test, validation\n",
    "\n",
    "def EncodeText(train, test, validation):\n",
    "    '''Кодировка текстовых данных путем TF-IDF'''\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df=2, max_df=0.95,ngram_range=(1,2),max_features=10000)\n",
    "    train = vectorizer.fit_transform(train)\n",
    "    test = vectorizer.transform(test)\n",
    "    validation = vectorizer.transform(validation)\n",
    "    return train, test, validation\n",
    "\n",
    "def RemainLettersNumsInLowerCase(data, columns_list):\n",
    "    '''Оставить только буквы в нижнем регистре и цифры'''\n",
    "    for column in columns_list:\n",
    "        data[column] = data[column].apply(lambda x: re.sub('[\\W]+', ' ', x.lower()))\n",
    "        \n",
    "def ThrowStopWords(series_column, stopwords_dict):\n",
    "    '''Получение датафрейма с текстои и выбрасывание русских стоп-слов'''\n",
    "    series = []\n",
    "    for i, string in enumerate(series_column):\n",
    "        series.append(' '.join(word for word in string.split() if stopwords_dict[word]==0))\n",
    "    return series\n",
    "\n",
    "def TrainTestValidationSplit(df):\n",
    "    '''Деление выборки на train, test, validation'''\n",
    "    \n",
    "    #так как в выборке есть объекты встречающиеся 1-2 раза, произведем их добавление вручную так, чтобы\n",
    "    #хотя бы 1 объект был в train, так же это полезно, когда для работы берется часть выборки\n",
    "    #с целью сократить временные затраты, в таких случаях также наблюдаются редкие объекты\n",
    "    \n",
    "    small_topics = []\n",
    "    val_counts = data['topic'].value_counts()\n",
    "    for ix, counts in enumerate(val_counts):\n",
    "        if counts <= 2:\n",
    "            small_topics.append(val_counts.index[ix])\n",
    "    \n",
    "    indexes = {}\n",
    "    all_ix = []\n",
    "    for x in small_topics:\n",
    "        l = []\n",
    "        for ix in df[df['topic'] == x].index:\n",
    "            l.append(ix)\n",
    "            all_ix.append(ix)\n",
    "        indexes[x] = l\n",
    "        \n",
    "    #удаление редких объектов из датасета, которые впоследствии будут добавлены вручную в train, test, validation\n",
    "    df_modif = df.drop(all_ix, axis = 0)\n",
    "    \n",
    "    #для выделения данных в случае, если была склейка text и title или нет\n",
    "    col_list = []\n",
    "    if 'fulldiscr' in df_modif.columns:\n",
    "        col_list.append('fulldiscr')\n",
    "    else:\n",
    "        col_list.append('text')\n",
    "        col_list.append('title')\n",
    "    col_list.append('tags')\n",
    "    \n",
    "    #деление на train, test, validation со стратификацией в соотношение 60% : 20% : 20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_modif.loc[:, col_list], df_modif['topic'],\n",
    "                                                        stratify=df_modif['topic'], test_size=0.2,\n",
    "                                                        random_state=SEED)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train,\n",
    "                                                      test_size=0.25, random_state=SEED)\n",
    "    #добавление редких объектов\n",
    "    for x, y_list in indexes.items():\n",
    "        length_y = len(y_list)\n",
    "        if length_y == 1:\n",
    "            X_train = X_train.append(df.loc[y_list[0], col_list])\n",
    "            y_train=y_train.append(pd.Series(df.loc[y_list[0], 'topic']))\n",
    "        elif length_y == 2:\n",
    "            X_train = X_train.append(df.loc[y_list[0], col_list])\n",
    "            X_test = X_test.append(df.loc[y_list[1], col_list])\n",
    "            y_train=y_train.append(pd.Series(df.loc[y_list[0], 'topic']))\n",
    "            y_test=y_test.append(pd.Series(df.loc[y_list[1], 'topic']))\n",
    "            \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainXgboost(X_train, X_test, y_train, y_test, n_classes, n_est=100, eta=0.05):\n",
    "    '''Обучение XGBoost классификатора и выдача accuracy'''\n",
    "    start = datetime.datetime.now()\n",
    "    params = {}\n",
    "    params['booster'] = 'gbtree'\n",
    "    params['objective'] = 'multi:softmax'\n",
    "    params['nthread'] = multiprocessing.cpu_count()\n",
    "    params['num_class'] = n_classes\n",
    "    params['seed'] = SEED\n",
    "    #параметры получены на сетке на неполной выборке(иначе бы не дождался)\n",
    "    params['n_estimators'] = n_est\n",
    "    params['eta'] = eta\n",
    "    \n",
    "    X_train = scipy.sparse.csc_matrix(X_train)\n",
    "    X_test = scipy.sparse.csc_matrix(X_test)\n",
    "    \n",
    "    xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    clf = xgb.train(params, xgb_train)\n",
    "    acc_score = accuracy_score(y_test, clf.predict(xgb_test))\n",
    "    \n",
    "    print('Time taken: {0}'.format(datetime.datetime.now() - start))\n",
    "    return acc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainLinearSVC(X_train, X_test, y_train, y_test, flag_balance=False):\n",
    "    '''Обучение LinearSVC с балансировкой классов и без'''\n",
    "    start = datetime.datetime.now()\n",
    "    if flag_balance == True:\n",
    "        clf_svc = LinearSVC(class_weight='balanced')\n",
    "    else:\n",
    "        clf_svc = LinearSVC()\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    print('Time taken: {0}'.format(datetime.datetime.now() - start))\n",
    "    return clf_svc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainNB(X_train, X_test, y_train, y_test, flag_balance=False):\n",
    "    '''Обучение наивного байесовского классификатора с технологией OneVsRest'''\n",
    "    start = datetime.datetime.now()\n",
    "    clf_nb = MultinomialNB()\n",
    "    clf = OneVsRestClassifier(clf_nb)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('Time taken: {0}'.format(datetime.datetime.now() - start))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удалим сразу url, так как полезной информации, на мой взгляд, он не несет, за исключением даты,\n",
    "#которая по большей части носит случайный характер\n",
    "#но можно попробовать посчитать частоту встречаемости какой-то статьи среди всех статей за опр прмежуток\n",
    "#data['url'] = data.loc[:,'url'].map(lambda x: datetime.datetime.strptime(re.search('\\d+/\\d+/\\d+',x).group(), '%Y/%m/%d').date())\n",
    "#data.rename({'url':'date'}, inplace=True, axis='columns')\n",
    "data_all = DropColumns(data_all, 'url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Общество</td>\n",
       "      <td>Миллиардер Илон Маск в резкой форме ответил бр...</td>\n",
       "      <td>Илон Маск назвал педофилом спасавшего детей из...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Рынки</td>\n",
       "      <td>США и их западные союзники рассматривают возмо...</td>\n",
       "      <td>США задумались о распечатывании нефтяного резерва</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tags                                               text  \\\n",
       "0  Общество  Миллиардер Илон Маск в резкой форме ответил бр...   \n",
       "1     Рынки  США и их западные союзники рассматривают возмо...   \n",
       "\n",
       "                                               title      topic  \n",
       "0  Илон Маск назвал педофилом спасавшего детей из...        Мир  \n",
       "1  США задумались о распечатывании нефтяного резерва  Экономика  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для ускорения процесса возьмем часть выборки\n",
    "data = data_all[:100*1000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обработаем пропущенные значения в данных\n",
    "data = HandleMissedData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Закодируем topic в числа\n",
    "data.loc[:,'topic'] = EncodeTarget(data.loc[:, 'topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объединим 2 признака, так как, кажется, это дает выигрыш в качестве\n",
    "data['fulldiscr'] = data['title'] + ' ' + data['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оставим в тексте только слова маленькими буквами и цифры \n",
    "RemainLettersNumsInLowerCase(data,['fulldiscr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбросим русские стоп-слова\n",
    "#data['fulldiscr'] = ThrowStopWords(data['fulldiscr'],stopwords_rus_dict)\n",
    "#Попытка показывает небольшое ухудшение классификаторов (на 1-2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n",
      "0.6 0.2 0.2\n"
     ]
    }
   ],
   "source": [
    "#Деление выборки на train, test, validation и проверка, что пропорции корректны\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = TrainTestValidationSplit(data)\n",
    "print(X_train.shape[0]==y_train.shape[0],X_test.shape[0]==y_test.shape[0],X_val.shape[0]==y_val.shape[0])\n",
    "print(X_train.shape[0]/data.shape[0],X_test.shape[0]/data.shape[0],X_val.shape[0]/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Остается произвести кодирование данных числами\n",
    "##Начнем с tags\n",
    "###one-hot encoding\n",
    "train_tags, test_tags, val_tags = EncodeTags(X_train['tags'], X_test['tags'], X_val['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Кодирование title и text\n",
    "###TF-IDF кодирование\n",
    "train_text, test_text, val_text = EncodeText(X_train['fulldiscr'],X_test['fulldiscr'],X_val['fulldiscr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объединение преобразованных массивов в один\n",
    "X_train_modif = np.hstack([train_text.toarray(), train_tags])\n",
    "X_test_modif = np.hstack([test_text.toarray(), test_tags])\n",
    "X_val_modif = np.hstack([val_text.toarray(), val_tags])\n",
    "\n",
    "###для scaled данных\n",
    "#X_train_modif = np.hstack([train_text_sc, train_tags])\n",
    "#X_test_modif = np.hstack([test_text_sc, test_tags])\n",
    "#X_val_modif = np.hstack([val_text_sc, val_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try diff algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:06:51.688717\n",
      "0.93255\n"
     ]
    }
   ],
   "source": [
    "acc = TrainXgboost(X_train_modif, X_test_modif, y_train, y_test, len(np.unique(y_train)))\n",
    "print(acc)\n",
    "#Time taken: 0:01:28.940291\n",
    "#0.9028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:00:17.339599\n",
      "0.9732\n"
     ]
    }
   ],
   "source": [
    "#Обучим линейный SVM без балансировки классов\n",
    "clf_SVC = TrainLinearSVC(X_train_modif, X_test_modif, y_train, y_test)\n",
    "print(accuracy_score(y_test, clf_SVC.predict(X_test_modif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:00:23.068698\n",
      "0.97415\n"
     ]
    }
   ],
   "source": [
    "#Обучим линейный SVM с балансировкой классов\n",
    "clf_SVC_bal = TrainLinearSVC(X_train_modif, X_test_modif, y_train, y_test, True)\n",
    "print(accuracy_score(y_test, clf_SVC_bal.predict(X_test_modif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:00:57.591083\n",
      "0.94655\n"
     ]
    }
   ],
   "source": [
    "#Обучим байесовский классификатор\n",
    "clf_nb = TrainNB(X_train_modif, X_test_modif, y_train, y_test)\n",
    "print(accuracy_score(y_test, clf_nb.predict(X_test_modif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.959871343465076, 0.9610108931956591)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на макро усредненные F1 меры у лучших классификаторов\n",
    "ConfusionMatrix(actual_vector=list(y_test), predict_vector=list(clf_SVC.predict(X_test_modif))).F1_Macro, \\\n",
    "ConfusionMatrix(actual_vector=list(y_test), predict_vector=list(clf_SVC_bal.predict(X_test_modif))).F1_Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97415\n",
      "0.912097349104367\n"
     ]
    }
   ],
   "source": [
    "#Проверим показатели accuracy и F1_macro на валидационной выборке у лучшего классификатора\n",
    "print(accuracy_score(y_val, clf_SVC.predict(X_val_modif)))\n",
    "print(ConfusionMatrix(actual_vector=list(y_val), predict_vector=list(clf_SVC.predict(X_val_modif))).F1_Macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
